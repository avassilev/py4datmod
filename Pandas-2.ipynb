{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "# R406: Using Python for data analysis and modelling\n",
    "\n",
    "<br> <br> \n",
    "\n",
    "## <center> Pandas â€” interaction with data sources and IO\n",
    "\n",
    "<br>\n",
    "\n",
    "<center> **Andrey Vassilev**\n",
    "\n",
    "<br> \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "1. Native Pandas functionality\n",
    "  - reading and writing CSV files\n",
    "  - reading and writing Excel files\n",
    "2. Using `pandas_datareader` module\n",
    "  - accessing Eurostat data\n",
    "  - accessing World Bank data\n",
    "  - accessing OECD data\n",
    "3. Pointers to other functionalities (**Note:** just references here! )\n",
    "   - SQL queries\n",
    "   - Stata, SAS and SPSS (via `savReaderWriter`) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading CSV files\n",
    "\n",
    "The basic function for reading CSV files is `read_csv()`. In its most basic form it takes only a string containing the name of the file to be imported. File will be imported as a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See https://github.com/fivethirtyeight/data/tree/master/college-majors\n",
    "# for a description of the data\n",
    "gradstudents = pd.read_csv(\"grad-students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradstudents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some useful parameters (see [docs](http://pandas.pydata.org/pandas-docs/stable/io.html) for a full description):\n",
    " - Pandas will try to infer the separator but if you know your file uses a special delimiter, pass something like `sep = \";\"`\n",
    " - If your data contains a header (=column names) but it is not positioned at row 1 (which is `header = 0` by default), you can skip the first few rows and pass something like `header = 3`. Pass `header = None` if you know your file contains no header.\n",
    " - More generally, you can pass something like `skiprows = 2` (skips the first two rows) or `skiprows = [0,2,3]` (skips specific row numbers) to skip rows at the beginning of a file. The parameter `skipfooter = n` skips the last `n` rows.\n",
    " - The parameter `names = [\"Col1\", \"Col2\"]` will ensure you get specific column names in your `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can read a file that is not in your current working directory. It is done like this:   \n",
    "```mj = pd.read_csv(r\"C:\\Users\\User\\Downloads\\majors-list.csv\")\n",
    "```\n",
    "\n",
    "Or you can even pass a specific URL to retrieve your CSV from the web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "women_stem = pd.read_csv(r\"https://github.com/fivethirtyeight/data/raw/master/college-majors/women-stem.csv\")\n",
    "women_stem.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Writing data to CSV files\n",
    "\n",
    "Data is written to a CSV file using the `to_csv()` method of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsshort = gradstudents.iloc[0:5,[1,3,5]]\n",
    "print(gsshort)\n",
    "gsshort.to_csv(\"gsshort.csv\", header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `to_csv()` method can also take parameters specifying:\n",
    " - the delimiter: `sep = \";\"`\n",
    " - whether to write the column names as a table header (True by default) but can be `header = False`\n",
    " - whether to write the index (True by default), can be `index = False`\n",
    "\n",
    "It can also take a path different than the current working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading Excel files\n",
    "\n",
    "Reading an Excel file can be done with the `read_excel()` function. It take a filename or a URL and returns a `DataFrame`. It can take other arguments, such a specific sheet name to read the data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratesraw = pd.read_excel(r\"http://www.bankofengland.co.uk/statistics/Documents/dl/251115fsg.xls\", sheetname= \"Data\")\n",
    "ratesraw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Other arguments can include skipping a specific number of rows, including a custom set of column names etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates = pd.read_excel(r\"251115fsg.xls\", \n",
    "                      sheetname = \"Data\", header = None, skiprows = 4, \n",
    "                      names = [\"date\",\"r\"])\n",
    "rates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also take the index from a specific column etc. In general, the approach and syntax are similar to those for CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates1 = pd.read_excel(r\"251115fsg.xls\", \n",
    "                      sheetname = \"Data\", header = None, skiprows = 4, \n",
    "                      names = [\"r\"], index_col=0)\n",
    "rates1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Writing Excel files\n",
    "\n",
    "**Big time warning: If you have an Excel file with the same name, the method shown below will essentially delete it and recreate it, including only the data from your dataframe. It will NOT update only specific sheets or ranges in an existing spreadsheet. If you need more advanced functionality, such as writing data to a specific range in a specific sheet, look elsewhere (e.g. the `openpyxl` library). **\n",
    "\n",
    "The dataframe method for writing to Excel is called `to_excel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates1[\"r\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates1.to_excel(\"rates1.xlsx\",sheet_name=\"rates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again, you can pass a number of parameters. For instance, as shown below, you can choose not to include the `DataFrame` index and columns. You can also specify a specific starting place in the sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates1.to_excel(\"rates1.xlsx\", sheet_name=\"rates\", header = False, \n",
    "                index = False, startcol=3, startrow=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting data directly from statistical sources\n",
    "\n",
    "- Pandas has an associated library called `pandas_datareader` which facilitates access to information from several popular data sources.\n",
    "- Examples include (see [here](https://pandas-datareader.readthedocs.io/en/latest/remote_data.html) for the full list):\n",
    "    - Eurostat      \n",
    "    - World Bank\n",
    "    - OECD\n",
    "    - Yahoo! Finance\n",
    "    - Google Finance\n",
    "    - St.Louis FED (FRED)\n",
    "- We shall look at the first three to get an idea how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting a Eurostat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Table tps00001 reports the population of a country \n",
    "# on 1 January of the respective year.\n",
    "df = web.DataReader(\"tps00001\", 'eurostat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An aside on working with `MultiIndex` object\n",
    "\n",
    "- The previous example shows that the columns are represented by a complex object, a `MultiIndex`. \n",
    "- This is essentially a nested structure of column names with headings, subheadings etc.\n",
    "- Here are a few common operations on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Selection\n",
    "df[\"Population on 1 January - total\"][\"Albania\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# One more level, produces a Series\n",
    "df[\"Population on 1 January - total\"][\"Albania\"][\"Annual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting several at once\n",
    "df[\"Population on 1 January - total\"][[\"Albania\",\"Azerbaijan\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# You can reassign the columns to simplify the structure\n",
    "df1 = df[\"Population on 1 January - total\"][[\"Albania\",\"Azerbaijan\"]]\n",
    "df1.columns = [\"Albania\",\"Azerbaijan\"]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting a World Bank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get final consumption expenditure (% of GDP) \n",
    "df = wb.download(indicator='NE.CON.TETC.ZS', country=[\"BG\",\"GB\",\"RU\"],\n",
    "                 start=2010,end=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are functions to get the country codes, search for keywords in indicator metadata etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting an OECD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Growth in GDP per capita, productivity and ULC\n",
    "df = web.DataReader('PDB_GR', 'oecd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"Austria\"][\"Total hours worked\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interfacing with a database\n",
    "\n",
    "**Note: No code examples here. Given for general info.**\n",
    "\n",
    "- Pandas has functions to retrieve information from databases and write back `DataFrame`s to databases.\n",
    "- This relies on using the powerful `SQLAlchemy` library\n",
    "- There are functions such as: \n",
    "   - `read_sql_table()` to retrieve a table from a database\n",
    "   - `read_sql_query()` to run a query against the database\n",
    "- A dataframe has a method `to_sql()` to write it as a table in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with Stata, SAS and SPSS files\n",
    "\n",
    "**Note: No code examples here. Given for general info.**\n",
    "\n",
    "- These file formats are relatively popular and you may have to read in and process data packaged in one of them.\n",
    "- The respective native Pandas methods are:\n",
    "  - `read_stata()`\n",
    "  - `read_sas()`\n",
    "- Pandas does not work natively with SPSS files. The `savReaderWriter` module provides IO functions to work with the `sav` format.\n",
    "- As a general rule, if you need to export data from Python to another program, the safest choice is probably to export in plain-text format and then read it into the other application."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
